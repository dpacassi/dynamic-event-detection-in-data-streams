# BA 2019

## Dynamische Eventerkennung in Datenströmen
- [Andreas Weiler, wele](https://www.zhaw.ch/de/ueber-uns/person/wele/)
- [Kurt Stockinger, stog](https://www.zhaw.ch/de/ueber-uns/person/stog/)
- [OAPA](https://tat.zhaw.ch/tpada/arbeit_vorschau.jsp?arbeitID=16040)

>  Wie kann in einem Datenstrom Ereignisse erkannt werden?
> 
> Bei der Suche nach neuen Ereignissen in Datenströmen, kommt es immer zum Problem was ein Ereignis genau ist. Wenn diese erste Frage geklärt ist kommt es aber zu weiteren Fragestellungen. Meistens reicht es nicht ein Ereignis statisch zu definieren, sondern die Definition entwickelt sich dynamisch über die Zeit. Die meisten Verfahren zu Ereigniserkennung werden aber bei Systemstart statisch eingestellt. Weiterhin muss man stets die Dynamik des Streams beachten, da es sonst du Blockaden und Überlauf im System kommen kann.
> 
> Ziel dieser Arbeit ist es eine Methodik zu entwickeln wie die genannten Aspekte auf geeigneten Datenströmen umgesetzt werden können. 

## Vorarbeit
- [Spark Data Frames](https://spark.apache.org/docs/latest/sql-getting-started.html)
- [Spark Streaming](https://spark.apache.org/docs/latest/streaming-programming-guide.html)
- [TensorFrames](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/5669198905533692/3647723071348946/3983381308530741/latest.html)

## Collected resources (non verified)
- [Creating Multi-language Pipelines with Apache Spark or Avoid Having to Rewrite spaCy into Java](https://blog.dominodatalab.com/creating-multi-language-pipelines-apache-spark-avoid-rewrite-spacy-java/)
- [Apache Spark — Tips and Tricks for better performance](https://hackernoon.com/apache-spark-tips-and-tricks-for-better-performance-cf2397cac11)
- [Apache Spark with Docker](https://github.com/gettyimages/docker-spark)
- [Zürich Apache Spark Meetup](https://www.meetup.com/spark-zurich/)

## Social Media Monitoring
- [Brandwatch](https://www.previon.ch/leistungen/social-media-monitoring/twint-brandwatch-referenz)
