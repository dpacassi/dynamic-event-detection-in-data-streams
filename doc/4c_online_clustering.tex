\subsection{Online Clustering}

\subsubsection{Design}

Detecting events in a stream of news articles will be achieved by using an online clustering approach. An event is described by the occurrence of multiple news articles to the same subject. The events of interest for this application are the discovery of new stories and the extension of existing stories. Thus we define our two types events as follows:

\begin{itemize}
    \item New event: A new cluster of news articles appears in the data stream, which describe the same story.
    \item Event extended: An existing story is extended by additional news articles.
\end{itemize}

HDBSCAN will be applied as the clustering method, using the optimal settings as discovered in the previous evaluation. Additional preprocessing of news articles before clustering is going to be explored as part of evaluation as well and will be implemented accordingly for the online clustering.

Since HDBSCAN only supports static data sets, the clustering will be done in batches using a time based sliding window approach. Events are detected by comparing the resulting clusters with the previous ones.

\begin{figure}[h]
    \centering

    \begin{tikzpicture}[scale=1]

        \draw[lightgray, line width=4pt] (0,.5) -- (4,.5);
        \draw[lightgray, dashed] (0,.5) -- (0,0);
        \draw[lightgray, dashed] (4,.5) -- (4,0);
        \node[align=right] at (-1,.5) {batch $n$};

        \draw[gray, line width=4pt] (1,1) -- (5,1);
        \draw[gray, dashed] (1,1) -- (1,0);
        \draw[gray, dashed] (5,1) -- (5,0);
        \node[align=right] at (-.2,1) {batch $n + 1$};

        \draw[darkgray, line width=4pt] (2,1.5) -- (6,1.5);
        \draw[darkgray, dashed] (2,1.5) -- (2,0);
        \draw[darkgray, dashed] (6,1.5) -- (6,0);
        \node[align=right] at (0.8,1.5) {batch $n + 2$};

        \node[align=center] at (5.5,-0.85) {$\triangle t$};
        \node[align=center] at (10,-0.5) {t};

        \draw [thick,->] (0,0) -- (10,0);
        \foreach \x in {0,...,9} \draw (\x,0.1) -- (\x,-0.1);

        \draw [thick,decorate,decoration={brace,amplitude=6pt,raise=0pt,mirror}] (5,-0.25) -- (6,-0.25);

        \end{tikzpicture}

    \caption{Timeline showing the sliding window approach}
    \label{fig:timeline}
\end{figure}

\paragraph{Finding pairs clusters}
Thus we define our two events as follows:
To be able to compare clusters of different batches with each other, we have to find pairs of clusters between batches, which describe the same story. This is done by applying the same assumptions as for the scoring function used in the evaluation. Therefore clusters are paired based on their similarity calculated with the Jaccard index as shown in equation \ref{equ:similarity}. If the similarity is above a certain threshold, both clusters are seen as describing the same story.

\paragraph{Sliding window}

An important consideration for determining existing or new clusters is the overlap of samples between batches. If the overlap is too small, similar clusters will no longer be detected as such, which would result in an increasingly high error rate. Finding optimal values for the step size between batches and the number of samples for each batch is therefore essential for our online clustering approach.

\subsubsection{Implementation}
\label{sec:online_clustering_implementation}

The online clustering implemented for this thesis does not operate in a true online setting, but rather it takes our existing test data and simulates a data stream over time. The simulated approach allows us to directly compare the resulting events with the ground truth and thus evaluate different settings. The implementation is done with Python and runs in a similar dockerized environment as the evaluation framework.

\paragraph{Comparing clusters}
To detect events between batches of clusterings,
we have find pairs of clusters describing the same story.
This problem is solved in the evaluation framework as part of the scoring function,
by calculating the similarity for each possible cluster pair.
The resulting time complexity is $O(n^2)$, which we deemed acceptable for the static evaluation.
However in a dynamic setting such as the online clustering, performance is an important factor,
since it restricts the lengths of the time delta between batches and the overall batch size.
Thus we decided to use Locality-Sensitive Hashing (LSH)\cite{alex2015practical} to find similar clusters.
This reduces the time complexity to $O(log(n))$.
The implementation for LSH is provided by the datasketch library\cite{eric_zhu_2017_290602}.

% TODO explain LSH?

\paragraph{Detecting Events}
Once we have found pairs of clusters, which represent the same story, detecting events becomes trivial.
For each pair we look for news articles, which are only present in the new cluster.
These articles are then summarized in as an extension of an existing event.
Clusters from the new batch without a matching cluster from the previous batch
are seen as new events.

\paragraph{Measuring the quality of events} 
Since events are themselves clusters of news articles, we apply the MP-Score to measure detected events against events taken from the ground truth. This gives an indication if the detected events contain the same news articles as true events and thus the rate of false positives and false negatives. Calculating the score is $O(n^2)$, but since the application runs on a simulated timeline, time complexity is only a minor concern. 

\paragraph{CLI} The application provides a command line interface to run the simulation with different parameters such as the start date, number of days to run and the batch size.

\begin{lstlisting}[caption=Command line interface for the online clustering, label={lst:cli_online_clustering}]
    usage: online_clustering.py [-h] [--full-cluster] [--verbose] [--rows ROWS]
                            [--full_rows FULL_ROWS] --date DATE
                            [--run_n_days RUN_N_DAYS] [--threshold THRESHOLD]

Run the batchwise clustering over a simulated stream of news articles.

required arguments:
  --date DATE           

optional arguments:
  -h, --help            show this help message and exit
  --full-cluster        run a full clustering once a day
                        default: False
  --verbose             
                        default: False
  --rows ROWS           number of samples to process per batch
                        default: 1000
  --full_rows FULL_ROWS
                        number of samples to process for the full clustering
  --run_n_days RUN_N_DAYS
                        number of days to run the batchwise clustering
                        default: 1
  --threshold THRESHOLD
                        similarity threshold for cluster matching
                        default: 0.75

\end{lstlisting}

% TODO clarify event vs topic vs story and be consistent with the usages!